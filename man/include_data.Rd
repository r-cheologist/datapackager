% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/include_data.R
\name{include_data}
\alias{include_data}
\title{include_data}
\usage{
include_data(
  object_to_include,
  type = c("auto", "object", "file", "file_rda", "file_rds", "url", "url_rda", "url_rds"),
  root = getwd(),
  data_catalogue = NULL,
  saved_elements = c("all", "data", "extdata"),
  distributable = TRUE,
  gitignore = !distributable,
  rbuildignore = !distributable,
  package_dependencies = NULL,
  parsing_function = NULL,
  parsing_options = NULL,
  user = NULL,
  password = NULL,
  save_catalogue = TRUE,
  compression_algo = NULL,
  hashing_algo = NULL
)
}
\arguments{
\item{object_to_include}{Single \code{\link{character}} representing a path
to a data file to be included (may also be an URL) or the name of an \code{R}
object.}

\item{type}{\code{\link{character}} object defining the supported data type.
See "Details'" for more.}

\item{root}{Single \code{\link{character}} representing the path of the
directory in which the package infrastructure is to reside. The directory
must have been created by \code{\link{init}} (ensuring the presence of the
infrastructure).}

\item{data_catalogue}{Single \code{link{character}} object representing the
relative path (within \code{root}) to the
\code{\link{data_catalogue}}-containing \code{R} data file within the
packaging infrastructure (defaulting to \code{data/data_catalogue.rda} if
set to \code{\link{NULL}}).}

\item{saved_elements}{\code{\link{character}} object indicating what aspects
of included data to save. \code{data} implies saving of (parsed) data objects
to the \code{data} directory within \code{root}, \code{extdata} saving of
unparsed files to \code{inst/extdata} within \code{root} (only used for the
\code{type}s \code{file} and \code{url}) and \code{all} is a shorthand for
both. When set to \code{NULL} \strong{only} list an additional entry in the
\code{\link{data_catalogue}}.}

\item{distributable}{Single \code{\link{logical}} shortcut for
\code{gitignore == TRUE && rbuildignore ==TRUE}.}

\item{gitignore}{Single \code{\link{logical}} indicating whether the
objects resulting from the integration of the data file into the package
infrastructure are to be listed in \code{.gitignore} to prevent their
integration into a \code{git} repository - handy e.g. in the case, where an
\code{R} package documenting a statistical analysis is to be distributed
without the underlying raw data.}

\item{rbuildignore}{Single \code{\link{logical}} indicating whether the
objects resulting from the integration of the data file into the package
infrastructure are to be listed in \code{.Rbuildignore} to provent their
integration into builds of the resulting \code{R}package - handy e.g. in the
case, where an \code{R} package documenting a statistical analysis is to be
distributed without the underlying raw data.}

\item{package_dependencies}{A \code{\link{character}} object naming \code{R}
extension packages required for \code{parsing_function} or dealing with the
\code{R} object to be included.}

\item{parsing_function}{Single \code{\link{character}} object naming the
function used for parsing the data file into an \code{R} object.}

\item{parsing_options}{Named \code{\link{list}} of options used by
\code{parsing_function} for reading the data file into an \code{R}
object.}

\item{user}{Single \code{\link{character}} object used for authentication
where retrieval of a remote data file requires it.}

\item{password}{Single \code{\link{character}} object used for
authentication where retrieval of a remote data file requires it.}

\item{save_catalogue}{Single \code{\link{logical}} indicating whether the
amended \code{\link{data_catalogue}} object is to be saved back to the
package infrastructure or just (silently) returned.}

\item{compression_algo}{Single \code{\link{character}} defining the method
for compression of \code{R} objects stored in the package infrastructure.
Defaults to the \code{default_compression_algo} \code{\link{attributes}} of
the \code{\link{data_catalogue}} used.}

\item{hashing_algo}{Single \code{\link{character}} defining the method
for cryptographic hashing (through \code{\link[digest]{digest}}; for details
see there) of \code{R} objects stored in the package infrastructure.Defaults
to the \code{default_hashing_algo} \code{\link{attributes}} of the
\code{\link{data_catalogue}} used.}
}
\value{
Returns a \code{\link{list}} of \code{\link{data_catalogue}}
characteristics via \code{\link{invisible}}.
}
\description{
Integrating data into \pkg{datapackageR}s infrastructure.
}
\details{
Supported data types are the following:
\describe{
  \item{\code{auto}:}{Instructs the function to attempt autonomous
    determination of the data type from \code{object_to_include} (default).}
  \item{\code{object}:}{Indicates \code{object_to_include} to be a (local)
    \code{R} object.}
  \item{\code{file}:}{Indicates \code{object_to_include} to be a (local)
    file requiring parsing using \code{parsing_function}.}
  \item{\code{url}:}{Indicates \code{object_to_include} to be a remote file
    requiring parsing using \code{parsing_function}.}
  \item{\code{file_rda} or \code{url_rda}:}{Indicate \code{object_to_include}
    to represent the path to a local (\code{file_*} or remote \code{url_*})
    \code{*.Rda/*.RData} file.}
  \item{\code{file_rds} or \code{url_rds}:}{Indicate \code{object_to_include}
    to represent the path to a local (\code{file_*} or remote \code{url_*})
    \code{*.Rds} file.}
}

The function proceeds as follows:
\enumerate{
  \item Inputs are checked and \code{type} determination is attempted
    (as required).
  \item If the data does not reside locally, it is downloaded in a first step
    using \code{\link{retrieve_remote_file}}.
  \item Next and for data requiring parsing, a \code{zip} compressed version
    of the file is saved to \code{inst/extdata} of the package
    infrastructure, using the internal function \code{save_zipfile}.
  \item For future integrity checking and as applicable, cryptographic hashes
    are captured for both the uncompressed and \code{zip}-compressed versions
    of the file (using \code{hashing_algo}). If \code{saved_elements} does
    \strong{not} contain \code{extdata}, the \code{zip}-file is subsequently
    purged from the package infrastructure.
  \item As necessary (see \code{type}) and using the function & options
    provided by \code{parsing_function} and \code{parsing_options},
    respectively, data files are parsed into an \code{R} object.
  \item For all \code{type}s the implied \code{R} object is cryptographically
    hashed (again using \code{hashing_algo}).
  \item If \code{data} is requested by \code{saved_elements}, the internal
    helper function \code{data_rename_and_writeout} is used to rename the
    objectto the original's \code{\link{basename}} and saved into the
    \code{data} directory of the package's infrastructure while utilizing the
    data compression given by \code{compression_algo}.
  \item If \code{package_dependencies} are given (for either parsing a file
    or dealing with an \code{R} object), the appropriate packages are
    integrated into the \code{DESCRIPTION} file using \pkg{devtools}-provided
    tools.
  \item A \pkg{roxygen2}-based documentation stub is installed into the
    target package infrastructure.
  \item Depending on the options \code{gitignore} and
    \code{rbuildignore}, \code{.gitignore} and \code{.Rbuildignore} in
    the top level of the resulting package infrastructure are amended using
    the internal function \code{manage_gitignore} and
    \code{\link[usethis]{use_build_ignore}}, respectively.
  \item Using the information gathered, the \code{\link{data_catalogue}} file
    is updated, saved into the worked-on package infrastructure (if
    \code{save_catalogue == TRUE}) and finally (invisibly) returned.
}
}
\examples{
# Load tools
library(magrittr)

# Generate package infrastructure
## Define a package root
pkg_root <- tempdir() \%>\%
  file.path("packagetest")

## Create the infrastructure
data_catalogue <- init(
  root = pkg_root)

## Investigate the data catalogue
data_catalogue \%>\%
  str()

# Add a local data file
## Create a dummy data file
data.frame(
    x   = 1,
    y   = 1:10,
    fac = sample(LETTERS[1:3], 10, replace = TRUE)) \%>\%
  write.table(
    file      = file.path(dirname(pkg_root), "data_dummy.tsv"),
    sep       = "\t",
    col.names = TRUE,
    row.names = FALSE)

## Add the dummy file to the existing package infrastructure
data_catalogue <- include_data(
  object_to_include = file.path(dirname(pkg_root), "data_dummy.tsv"),
  root = pkg_root,
  parsing_function = "read.csv",
  parsing_options = list(sep = "\t", stringsAsFactors = FALSE))

## Investigate the data catalogue
data_catalogue \%>\%
  str()

# Add a remote file that needs parsing (from Billing et al. (2016).
# Comprehensive transcriptomic and proteomic characterization of human
# mesenchymal stem cells reveals source specific cellular markers. Sci Rep 6,
# 21507. Licensed under the Creative Commons Attribution 4.0 International
# License. http://creativecommons.org/licenses/by/4.0/
# EXCLUDED FROM BUILDS
\donttest{
  if(requireNamespace("readxl", quietly = TRUE))
  {
    require(readxl)
    ## Complicated URL generation to circumvent line length restrictions
    tmp_url <- paste0(
      c("http://www.nature.com/article-assets/npg/srep",
        "2016/160209/srep21507/extref/srep21507-s4.xls"),
      collapse = "/")
    data_catalogue <- include_data(
      object_to_include = tmp_url,
      root = pkg_root,
      parsing_function = "read_excel",
      parsing_options = list(skip = 1),
      package_dependencies = "readxl",
      distributable = FALSE)

    ## Investigate the data catalogue
    data_catalogue \%>\%
      str()
  }
}

# Add a local object
local_data_object <-list(A = LETTERS, B = letters)
data_catalogue <- include_data(
  object_to_include = "local_data_object",
  root = pkg_root)

# Add a remote *.Rda (pasted to make CRAN line length requirements)
\donttest{
  data_catalogue <- include_data(
    object_to_include = paste(
      "https://bitbucket.org",
      "graumannlabtools",
      "datapackager",
      "downloads",
      "remote_rda.Rda",
       sep = "/"),
   root = pkg_root)

# Add a remote *.Rds (pasted to make CRAN line length requirements)
  data_catalogue <- include_data(
    object_to_include = paste(
      "https://bitbucket.org",
      "graumannlabtools",
      "datapackager",
      "downloads",
      "remote_rds.Rds",
      sep = "/"),
    root = pkg_root)
}

# Investigate the data catalogue
data_catalogue \%>\%
  str()

# Have a look at the package structure
list.files(pkg_root, recursive = TRUE)

# Clean up the package root - ensure proper example testing by R CMD check
unlink(pkg_root, recursive = TRUE)
}
\seealso{
\code{\link{init}}, \code{\link{remove_data}},
\code{\link[digest]{digest}}, \code{\link{data_catalogue}}
}
\author{
Johannes Graumann
}
